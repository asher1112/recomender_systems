{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "import pickle\n",
    "\n",
    "# import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the  data\n",
    "\n",
    "with open('../data/user2movie.pkl', 'rb') as f:\n",
    "  user2movie = pickle.load(f)\n",
    "\n",
    "with open('../data/movie2user.pkl', 'rb') as f:\n",
    "  movie2user = pickle.load(f)\n",
    "\n",
    "with open('../data/usermovie2rating.pkl', 'rb') as f:\n",
    "  usermovie2rating = pickle.load(f)\n",
    "\n",
    "\n",
    "# test data\n",
    "\n",
    "with open('../data/user2movie_test.pkl', 'rb') as f:\n",
    "  user2movie_test = pickle.load(f)\n",
    "\n",
    "with open('../data/movie2user_test.pkl', 'rb') as f:\n",
    "  movie2user_test = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('../data/usermovie2rating_test.pkl', 'rb') as f:\n",
    "  usermovie2rating_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average rating of each Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 44.5 ms, sys: 477 Âµs, total: 45 ms\nWall time: 45.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create dictonary with user as key and average rating as value\n",
    "avg_rating_for_movie = {}\n",
    "for i in movie2user:\n",
    "    \n",
    "    list_users = movie2user[i]\n",
    "    ratings = []\n",
    "    \n",
    "    for j in list_users:\n",
    "        ratings.append(usermovie2rating[(j , i)])\n",
    "        \n",
    "    avg_rating = sum(ratings) / len(ratings)\n",
    "    avg_rating_for_movie[i] = avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mse as the metric\n",
    "\n",
    "# calculate mse from 2 dictonarys\n",
    "def calc_mse(pred_dict , actual_dict):\n",
    "    pred_keys = list(pred_dict.keys())\n",
    "    pred_list = []\n",
    "    actual_list = []\n",
    "    \n",
    "    for i in pred_keys:\n",
    "        actual_list.append(actual_dict[i])\n",
    "        pred_list.append(pred_dict[i])\n",
    "    pred_array = np.asarray(pred_list)\n",
    "    actual_array = np.asarray(actual_list)\n",
    "    \n",
    "    mse = np.sum((pred_array - actual_array)**2) / len(pred_array)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the baseline model will be using the average rating as the rating for each user\n",
    "\n",
    "# store items in dictionary\n",
    "\n",
    "def baseline(movie2user = movie2user , usermovie2rating = usermovie2rating):\n",
    "    baseline_predictions = {}\n",
    "    num_of_movies = len(user2movie.keys())\n",
    "    for i in range(num_of_movies):\n",
    "        users = movie2user[i]\n",
    "        for j in users:\n",
    "            baseline_predictions[(j , i)] = avg_rating_for_movie[i]\n",
    "    return baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baseline_predictions = baseline(movie2user= movie2user , usermovie2rating = usermovie2rating)\n",
    "test_baseline_predictions = baseline(movie2user= movie2user_test , usermovie2rating = usermovie2rating_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8159394158738645"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "calc_mse(pred_dict=train_baseline_predictions , actual_dict=usermovie2rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8316568077899196"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "calc_mse(pred_dict= test_baseline_predictions , actual_dict= usermovie2rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The weights for item - item colabarative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are given by:\n",
    "\n",
    "$$ w_{jj'} = \\frac{\\sum_{i \\in \\psi_{jj'}} (r_{ij} -\\bar{r_{j}})(r_{ij'} -\\bar{r_{j'}}) }{\\sqrt{\\sum_{i \\in \\psi_{jj'}}(r_{ij} - \\bar{r}_{j})^{2}}   \\sqrt{\\sum_{i \\in \\psi_{jj'}} (r_{ij'} - \\bar{r}_{j'})^{2} } } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{jj'}$ - the weights between 2 movies\n",
    "\n",
    "$\\psi_{jj'}$ - set of users who watched by both j and j'\n",
    "\n",
    "$r_{j'i}$ - rating user i gave rating j'\n",
    "\n",
    "$r_{ij}$ - rating user i gave rating moive j\n",
    "\n",
    "$\\bar{r_{i}}$ - average rating of movie j\n",
    "\n",
    "$\\bar{r_{i'}}$ - average rating of movie j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# generates an array of ratigns\n",
    "def array_of_ratings (movies , shared_users):\n",
    "    my_list = []\n",
    "    for i in shared_users:\n",
    "        my_list.append(usermovie2rating[i , movies])\n",
    "    return np.asarray(my_list)\n",
    "\n",
    "# formula for calculating weights\n",
    "def calculate_weights(dev_0 , dev_1):\n",
    "    return np.dot(dev_0 , dev_1) / (np.sqrt(np.sum(dev_0**2)) * np.sqrt(np.sum(dev_1**2)))\n",
    "\n",
    "# returns only the 25 most relavant key value pairs for the dictionary\n",
    "def filter_dictonary(my_dict , num = 25):\n",
    "    my_series = pd.Series(my_dict)\n",
    "    my_series2 = my_series.copy()    \n",
    "    # decided by larged modulo value as negative values have equal use to positive values\n",
    "    index = my_series.apply(lambda x : np.abs(x)).sort_values(ascending = False).head(num).index.to_list()\n",
    "    return my_series.loc[index].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total time 13.275274276733398 in seconds\n"
     ]
    }
   ],
   "source": [
    "#total complexity O(M^2 * N) where N is number of users and M is number of movies\n",
    "start = time.time()\n",
    "\n",
    "#num of movies\n",
    "movies = len(movie2user.keys())\n",
    "#keep all values stored inside a dictionary\n",
    "all_movie_weights = {}\n",
    "\n",
    "#number of common users required\n",
    "l = 5\n",
    "for m in range(movies): #O(M)\n",
    "\n",
    "    # weights dictionary\n",
    "    weights_dict = {}\n",
    "    users_m = set(movie2user[m])\n",
    "    for j in movie2user: #O(M)\n",
    "        if j is not m:\n",
    "            users_j = set(movie2user[j]) #O(N)\n",
    "            shared_users = users_j & users_m\n",
    "\n",
    "            if len(shared_users) >= l:\n",
    "            \n",
    "                # ratings of shared movies by both users\n",
    "                arr_0_ratings = array_of_ratings(m , shared_users)\n",
    "                arr_1_ratings = array_of_ratings(j , shared_users)\n",
    "            \n",
    "                # average ratings by both users\n",
    "                avg_r0 = avg_rating_for_movie[m]\n",
    "                avg_r1 = avg_rating_for_movie[j]\n",
    "\n",
    "                weights_dict[j] = calculate_weights(arr_1_ratings - avg_r1 , arr_0_ratings - avg_r0)\n",
    "    sorted_dict = filter_dictonary(weights_dict)\n",
    "    all_movie_weights[m] = sorted_dict\n",
    "    \n",
    "    # keep track of where we are at during while generating the weights\n",
    "#     if (m+1) % 200 == 0:\n",
    "#         print('number of cycles passed:' , m + 1)\n",
    "#         print('time taken so far is ',  time.time() - start , 'seconds')\n",
    "    \n",
    "    \n",
    "end = time.time()\n",
    "print('total time' , end - start , 'in seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary as it takes a long time to generate again\n",
    "\n",
    "with open('../data/item_item_weights.pickle', 'wb') as f:\n",
    "    pickle.dump(all_movie_weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Item Colabarative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{dev}(i , j) = \\frac{ \\sum_{i' \\in \\Omega_{j}}  w_{ii'}( r(i' , j) - \\bar{r_{i'}})}{\\sum_{i' \\in \\Omega_{i'}}|w_{ii'}| } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s(i , j) = \\bar{r_{i}} + \\hat{dev}( i , j ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s(i , j) - rating user i gives to item j\n",
    "\n",
    "$\\bar{r_{j}}$ - average rating of movie j\n",
    "\n",
    "$\\hat{dev(i , j)}$ - weighted deviation of movie j other users i'\n",
    "\n",
    "$\\hat{r(i , j')}$ - rating user i gave to item j'\n",
    "\n",
    "$\\bar{r_{j'}}$ - average rating of movie j'\n",
    "\n",
    "$w_{jj'}$ - weight between movie j and j'\n",
    "\n",
    "$\\Omega_{j'}$ - all relavant movies with relavant shared user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to make predictions on the data we have\n",
    "\n",
    "def make_predictions(all_movie_weights = all_movie_weights , user2movie = user2movie \n",
    "                                , movie2user = movie2user, usermovie2rating = usermovie2rating):\n",
    "    # movies\n",
    "    movies = len(movie2user.keys())\n",
    "    \n",
    "    # keep all the predictions in a dictionary\n",
    "    pred_movie_user2rating = {}\n",
    "    \n",
    "    for m in range(movies):\n",
    "        \n",
    "        #weights of each user\n",
    "        movies_weights = all_movie_weights[m]\n",
    "        \n",
    "        # all movies watched by our relavant user\n",
    "        users = movie2user[m]\n",
    "        \n",
    "        for u in users:\n",
    "\n",
    "            # find common movies\n",
    "            common_movies = set(movies_weights.keys())\n",
    "            \n",
    "            # set of all users who have rated move m\n",
    "            all_movies_user_u = set(user2movie[u])\n",
    "\n",
    "\n",
    "            # set of users who have rated moive m and have a weight in dictionary\n",
    "            relavant_movies = all_movies_user_u & common_movies\n",
    "            \n",
    "            denominator = 0\n",
    "            numerator = 0\n",
    "            for i in relavant_movies:\n",
    "                numerator += all_movie_weights[m][i] * (usermovie2rating[(u , i)] - avg_rating_for_movie[i])\n",
    "                denominator += float(np.abs(all_movie_weights[m][i]))\n",
    "            \n",
    "            if int(denominator) != 0:\n",
    "                pred_movie_user2rating[(u , m)] = avg_rating_for_movie[m] +  numerator/denominator\n",
    "            else:\n",
    "                pred_movie_user2rating[( u , m)] = avg_rating_for_movie[m]\n",
    "    \n",
    "    return pred_movie_user2rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2.21 s, sys: 0 ns, total: 2.21 s\nWall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make predictions from train data\n",
    "train_data = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15406"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# test data 2\n",
    "test_data = make_predictions(movie2user = movie2user_test)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4388296147947832"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# evaluate train by mse\n",
    "calc_mse(pred_dict= train_data  , actual_dict= usermovie2rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5829560450628802"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# evaluate test by mse\n",
    "calc_mse(pred_dict= test_data  , actual_dict= usermovie2rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to predict a set of ratings for each user for movies they have not watched\n",
    "\n",
    "#number of movies\n",
    "set_of_movies = set(movie2user.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrated_movie2user = {}\n",
    "for key in movie2user:\n",
    "    movies_watched_train = set(movie2user[key])\n",
    "    movies_watched_test = set(movie2user_test[key])\n",
    "    movies_not_watched = set_of_movies - (movies_watched_train | movies_watched_test)\n",
    "    for i in movies_not_watched:\n",
    "        if key not in unrated_movie2user:\n",
    "            unrated_movie2user[key] = [i]\n",
    "        else:\n",
    "            unrated_movie2user[key].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on unwatched moives\n",
    "predictions = make_predictions(movie2user = unrated_movie2user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12970"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37964bitanaconda3virtualenvcb2bcb0a39c044c69eaabd6a65d0bcb7",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "0ef71bcca125705d50a4d750835226bed54ee4230dfddfaafb17cd4b61398cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}